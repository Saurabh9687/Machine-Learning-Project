{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CPN3HOC-zUU7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score, confusion_matrix"
      ],
      "metadata": {
        "id": "u8GuJqdzZ7pK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Write code to read the dataset in Data Q1.txt into two numpy arrays: X and y containing\n",
        "the features and labels respectively."
      ],
      "metadata": {
        "id": "nCYzNHNMhdnH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rwYc8aZ588Sn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from urllib.request import urlopen\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/Saurabh9687/IE-506--2-/main/Data_Q1.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6ha65K09HYQ",
        "outputId": "31724e6c-d5f3-4701-b756-6b64c593571f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label [ 1 -1 -1 ...  1 -1  1]\n",
            "Features [[1 1 1 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 1 1 1]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_svmlight_file\n",
        "\n",
        "with urlopen(url) as f:\n",
        "    X, y = load_svmlight_file(f)\n",
        "\n",
        "X = X.toarray().astype('int32')\n",
        "y = y.astype('int32')\n",
        "print(\"Label\",y)\n",
        "print(\"Features\",X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j14T7pFtJbGn",
        "outputId": "303acfb9-4d59-4a95-cca2-e0ea46bb9dc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset has 4143 samples\n"
          ]
        }
      ],
      "source": [
        "print(\"Dataset has {} samples\".format(*X.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Print the number of classes in the data set and the number of samples belonging to\n",
        "each class. Indicate if there is class imbalance issue."
      ],
      "metadata": {
        "id": "RmiZVLU_huKw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrxs8IU8hheq",
        "outputId": "fe64fd24-bf9c-456f-e4b5-1e24e63bdd17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes =  2\n",
            "number of samples belonging to class 1 =  2210\n",
            "number of samples belonging to class -1 =  1933\n"
          ]
        }
      ],
      "source": [
        "unique_values = np.unique(y)\n",
        "count = len(unique_values)\n",
        "print(\"Number of classes = \",count)\n",
        "count1 = np.sum(y==1)\n",
        "count2 = np.sum(y==-1)\n",
        "print(\"number of samples belonging to class 1 = \",count1)\n",
        "print(\"number of samples belonging to class -1 = \",count2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**No , there is no class imbalance issue.**\n"
      ],
      "metadata": {
        "id": "PBWQBnGliRJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "C) Split the data into two sets such that 80% of the data is considered as set T1 and\n",
        "20% of the data is considered as set T2. Justify if set T1 and set T2 have similar class label proportions.\n",
        "2"
      ],
      "metadata": {
        "id": "ez78ftSKiOpM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3k0HvhkTiilt"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "T1_X, T2_X, T1_y, T2_y = train_test_split(X, y, test_size = 0.20, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_T1_1 = np.sum(T1_y==1)\n",
        "count_T2_1 = np.sum(T2_y==1)\n",
        "count_T1_2 = np.sum(T1_y==-1)\n",
        "count_T2_2 = np.sum(T2_y==-1)\n",
        "print(\"In set T1 number of samples belonging to class 1 = \",count_T1_1)\n",
        "print(\"In set T1 number of samples belonging to class -1 = \",count_T1_2)\n",
        "print(\"In set T2 number of samples belonging to class 1 = \",count_T2_1)\n",
        "print(\"In set T2 number of samples belonging to class -1 = \",count_T2_2)\n",
        "print(\"Label proportion in T1 = \",count_T1_1/count_T1_2)\n",
        "print(\"Label proportion in T1 = \",count_T2_1/count_T2_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6cx24PIiqHb",
        "outputId": "391eeeae-e6d6-4e47-b604-146a96371192"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In set T1 number of samples belonging to class 1 =  1762\n",
            "In set T1 number of samples belonging to class -1 =  1552\n",
            "In set T2 number of samples belonging to class 1 =  448\n",
            "In set T2 number of samples belonging to class -1 =  381\n",
            "Label proportion in T1 =  1.1353092783505154\n",
            "Label proportion in T1 =  1.1758530183727034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**So, set T1 and set T2 have quite similar class label proportions.**\n"
      ],
      "metadata": {
        "id": "O-txKD3tjdWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "d) Using T1 as training data, train each of the following algorithms by tuning only the\n",
        "hyperparameters specified below (keep all other hyperparameters fixed to the default values in\n",
        "scikit-learn):"
      ],
      "metadata": {
        "id": "EuFOatJ0jwWk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GSst-PGCf8KY"
      },
      "outputs": [],
      "source": [
        "train_X, train_y = T1_X, T1_y\n",
        "test_X, test_y = T2_X, T2_y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sensitivity_score(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    return sensitivity"
      ],
      "metadata": {
        "id": "RtSuenVmZUsG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def specificity_score(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    specificity = tn / (tn + fp)\n",
        "    return specificity"
      ],
      "metadata": {
        "id": "koqUERVAZXjo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix(train_y,pred_train,test_y,pred):\n",
        "  accuracy_T1 = accuracy_score(train_y,pred_train)\n",
        "  precision_T1 = precision_score(train_y,pred_train)\n",
        "  recall_T1 = recall_score(train_y,pred_train)\n",
        "  specificity_T1 = specificity_score(train_y,pred_train)\n",
        "  sensitivity_T1 = sensitivity_score(train_y,pred_train)\n",
        "  accuracy_T2 = accuracy_score(test_y,pred)\n",
        "  precision_T2 = precision_score(test_y,pred)\n",
        "  recall_T2 = recall_score(test_y,pred)\n",
        "  specificity_T2 = specificity_score(test_y,pred)\n",
        "  sensitivity_T2 = sensitivity_score(test_y,pred)\n",
        "  return  accuracy_T1, precision_T1, recall_T1, specificity_T1, sensitivity_T1, accuracy_T2, precision_T2, recall_T2, specificity_T2,sensitivity_T2"
      ],
      "metadata": {
        "id": "2_MDizT8anj0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "i) Logistic regression with L2 regularizer (Hyperparameter: regularization constant C)"
      ],
      "metadata": {
        "id": "9-hjhR3Aj3pN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For smaller datasets, we would use smaller ranges and perform a more targeted search, while for larger datasets, we would consider larger ranges and perform a more broad search."
      ],
      "metadata": {
        "id": "nO5A0lSAp-EJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Higher values of C lead to less regularization, while lower values lead to more regularization.\n",
        "\n",
        "Considering a range of values for C from 0.1 to 10, with a logarithmic spacing."
      ],
      "metadata": {
        "id": "U-81vjgklGyc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdZrTuyiraiT"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "lg_l2 = LogisticRegression(penalty=\"l2\", max_iter=10000)\n",
        "param_grid = {'C':np.logspace(-1, 1, 3)}\n",
        "\n",
        "CV_lg_l2 = GridSearchCV(estimator=lg_l2, param_grid=param_grid, cv= 5, n_jobs=-1)\n",
        "CV_lg_l2.fit(train_X, train_y)\n",
        "best_C = CV_lg_l2.best_params_['C']\n",
        "print(CV_lg_l2.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1Z-rVPeraYI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "lg_l2_1=LogisticRegression(penalty=\"l2\",C = best_C)\n",
        "lg_l2_1.fit(train_X, train_y)\n",
        "pred_lg_l2=lg_l2_1.predict(test_X)\n",
        "print(\"Accuracy for Logistic Regression with L2 regularizer on CV data: \",accuracy_score(test_y,pred_lg_l2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lg_l2_1.fit(train_X, train_y)\n",
        "pred_train_lg_l2=lg_l2_1.predict(train_X)"
      ],
      "metadata": {
        "id": "gVOqBQ3qcDWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_lg_l2_T1, precision_lg_l2_T1, recall_lg_l2_T1, specificity_lg_l2_T1, sensitivity_lg_l2_T1, accuracy_lg_l2_T2, precision_lg_l2_T2, recall_lg_l2_T2, specificity_lg_l2_T2,sensitivity_lg_l2_T2 = matrix(train_y,pred_train_lg_l2,test_y,pred_lg_l2)"
      ],
      "metadata": {
        "id": "LZgLpQ8_cEzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ii) Logistic regression with L1 regularizer (Hyperparameter: regularization constant C)"
      ],
      "metadata": {
        "id": "h4ZzQWAYj-yk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Higher values of C lead to less regularization, while lower values lead to more regularization.\n",
        "\n",
        "Considering a range of values for C from 0.1 to 10, with a logarithmic spacing."
      ],
      "metadata": {
        "id": "nTnI-IPPlrGc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn3qag0iv21V"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "lg_l1 = LogisticRegression(penalty=\"l1\",solver = 'saga', max_iter=100000)\n",
        "param_grid = {'C':np.logspace(-1, 1, 3)}\n",
        "\n",
        "CV_lg_l1 = GridSearchCV(estimator=lg_l1,param_grid=param_grid, cv= 5)\n",
        "CV_lg_l1.fit(train_X, train_y)\n",
        "best_C_lg_l1 = CV_lg_l1.best_params_['C']\n",
        "print(CV_lg_l1.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdPoZE0ov3YQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "lg_l1_1=LogisticRegression(penalty=\"l1\",C = best_C_lg_l1,solver = 'saga')\n",
        "lg_l1_1.fit(train_X, train_y)\n",
        "pred_lg_l1=lg_l1_1.predict(test_X)\n",
        "print(\"Accuracy for Logistic Regression with L2 regularizer on CV data: \",accuracy_score(test_y,pred_lg_l1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lg_l1_1.fit(train_X, train_y)\n",
        "pred_train_lg_l1=lg_l1_1.predict(train_X)"
      ],
      "metadata": {
        "id": "wxf3zU62gsYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_lg_l1_T1, precision_lg_l1_T1, recall_lg_l1_T1, specificity_lg_l1_T1, sensitivity_lg_l1_T1, accuracy_lg_l1_T2, precision_lg_l1_T2, recall_lg_l1_T2, specificity_lg_l1_T2,sensitivity_lg_l1_T2 = matrix(train_y,pred_train_lg_l1,test_y,pred_lg_l1)"
      ],
      "metadata": {
        "id": "zOLtYc7HggQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "iii. Soft-margin SVM with L2 regularizer (Hyperparameter: regularization constant C)"
      ],
      "metadata": {
        "id": "L7hvOkf4kE_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Higher values of C lead to less regularization, while lower values lead to more regularization.\n",
        "\n",
        "Considering a range of values for C from 0.1 to 10, with a logarithmic spacing."
      ],
      "metadata": {
        "id": "HywOq3sUmw3j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0XiNXQ0PqN_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "046b2bbc-bb87-4b25-e52b-1d6611717a22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 0.1}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "sm_svm_l2 = LinearSVC(penalty=\"l2\", max_iter=100000)\n",
        "param_grid = {'C':np.logspace(-1, 1, 3)}\n",
        "\n",
        "CV_sm_svm_l2 = GridSearchCV(estimator=sm_svm_l2, param_grid=param_grid, cv= 5)\n",
        "CV_sm_svm_l2.fit(train_X, train_y)\n",
        "best_sm_svm_l2 = CV_sm_svm_l2.best_params_['C']\n",
        "print(CV_sm_svm_l2.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Zb5O7KD6qNz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3db15b2f-bd16-465c-d72b-9b98fb6bc214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Soft-margin SVM with L2 regularizer on CV data:  0.8914354644149578\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "sm_svm_l2=LinearSVC(penalty=\"l2\",C = best_sm_svm_l2)\n",
        "sm_svm_l2.fit(train_X, train_y)\n",
        "pred_sm_svm_l2=sm_svm_l2.predict(test_X)\n",
        "print(\"Accuracy for Soft-margin SVM with L2 regularizer on CV data: \",accuracy_score(test_y,pred_sm_svm_l2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm_svm_l2.fit(train_X, train_y)\n",
        "pred_train_sm_svm_l2=sm_svm_l2.predict(train_X)"
      ],
      "metadata": {
        "id": "FD_8f4pXZjQR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_sm_svm_l2_T1, precision_sm_svm_l2_T1, recall_sm_svm_l2_T1, specificity_sm_svm_l2_T1, sensitivity_sm_svm_l2_T1, accuracy_sm_svm_l2_T2, precision_sm_svm_l2_T2, recall_sm_svm_l2_T2, specificity_sm_svm_l2_T2,sensitivity_sm_svm_l2_T2 = matrix(train_y,pred_train_sm_svm_l2,test_y,pred_sm_svm_l2)"
      ],
      "metadata": {
        "id": "Ds8HUpkMZhE_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "iv. Soft-margin SVM with L1 regularizer (Hyperparameter: regularization constant C)"
      ],
      "metadata": {
        "id": "2wk4bvj4kI8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Higher values of C lead to less regularization, while lower values lead to more regularization.\n",
        "\n",
        "Considering a range of values for C from 0.1 to 10, with a logarithmic spacing."
      ],
      "metadata": {
        "id": "dTNn6NRSm03D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9etH8b_VgtIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e76ece-ea31-40d3-851f-bd78039c54eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 0.1}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "sm_svm = LinearSVC(penalty=\"l1\", max_iter=100000, loss=\"squared_hinge\", dual=False, class_weight='balanced', tol=1e-3,)\n",
        "param_grid = {'C':np.logspace(-1, 1, 3)}\n",
        "\n",
        "CV_sm_svm = GridSearchCV(estimator=sm_svm, param_grid=param_grid, cv= 5)\n",
        "CV_sm_svm.fit(train_X, train_y)\n",
        "best_sm_svm_l1  = CV_sm_svm.best_params_['C']\n",
        "print(CV_sm_svm.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "MFCivCu0gs9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36b5c7bf-a7ff-4888-d7d2-dd88e4773394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Soft-margin SVM with L1 regularizer on CV data:  0.8926417370325693\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "sm_svm_l1=LinearSVC(penalty=\"l1\",C = best_sm_svm_l1,loss=\"squared_hinge\", dual=False, class_weight='balanced', tol=1e-3, )\n",
        "sm_svm_l1.fit(train_X, train_y)\n",
        "pred_sm_svm_l1=sm_svm_l1.predict(test_X)\n",
        "print(\"Accuracy for Soft-margin SVM with L1 regularizer on CV data: \",accuracy_score(test_y,pred_sm_svm_l1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm_svm_l1.fit(train_X, train_y)\n",
        "pred_train_sm_svm_l1=sm_svm_l1.predict(train_X)"
      ],
      "metadata": {
        "id": "0J1mjP83W-Uh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_sm_svm_l1_T1, precision_sm_svm_l1_T1, recall_sm_svm_l1_T1, specificity_sm_svm_l1_T1, sensitivity_sm_svm_l1_T1, accuracy_sm_svm_l1_T2, precision_sm_svm_l1_T2, recall_sm_svm_l1_T2,specificity_sm_svm_l1_T2, sensitivity_sm_svm_l1_T2 = matrix(train_y,pred_train_sm_svm_l1,test_y,pred_sm_svm_l1)"
      ],
      "metadata": {
        "id": "53bhHIvcVrNQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "v. Kernel SVM with RBF kernel (Hyperparameter: kernel parameter Î³)"
      ],
      "metadata": {
        "id": "DN75edXKkLwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Higher values of gamma lead to more complex decision boundaries, while lower values lead to simpler decision boundaries.\n",
        "\n",
        "Considering a range of values for gamma from 0.1 to 10, with a logarithmic spacing."
      ],
      "metadata": {
        "id": "ETC5-CjdoaA9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdfeobHmuJOO"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "param_grid = {'kernel': ['rbf'], 'gamma': np.logspace(-1, 1, 3)}\n",
        "\n",
        "svc = svm.SVC( max_iter=10000, class_weight='balanced')\n",
        "CV_svc = GridSearchCV(estimator=svc, param_grid=param_grid, cv= 5)\n",
        "CV_svc.fit(train_X, train_y)\n",
        "best_gamma_svc = CV_svc.best_params_['gamma']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hkR83dHdoU6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "svc1=svm.SVC(gamma=best_gamma_svc)\n",
        "svc1.fit(train_X, train_y)\n",
        "pred_svc=svc1.predict(test_X)\n",
        "print(\"Accuracy for Kernel SVM with RBF kernel on CV data: \",accuracy_score(test_y,pred_svc))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svc1.fit(train_X, train_y)\n",
        "pred_train_svc=svc1.predict(train_X)"
      ],
      "metadata": {
        "id": "Fm0ohGLPh0H8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_svc_T1, precision_svc_T1, recall_svc_T1, specificity_svc_T1, sensitivity_svc_T1, accuracy_svc_T2, precision_svc_T2, recall_svc_T2,specificity_svc_T2, sensitivity_svc_T2 = matrix(train_y,pred_train_svc,test_y,pred_svc)"
      ],
      "metadata": {
        "id": "HqGBZ0FLh09d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vi. KNN (Hyperparameter: number of neighbors)"
      ],
      "metadata": {
        "id": "e3ShJppIkPkg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "k controls the number of neighbors to consider for each prediction.\n",
        "\n",
        "Considering a range of values for k from 1 to 6."
      ],
      "metadata": {
        "id": "GXVO0DMeo1NM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff5vQ-QccWWr"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "kNc = KNeighborsClassifier()\n",
        "param_grid = {'n_neighbors': range(1, 6,2)}\n",
        "CV_kNc = GridSearchCV(estimator=kNc, param_grid=param_grid, cv= 5)\n",
        "CV_kNc.fit(train_X, train_y)\n",
        "best_n_kNc = CV_kNc.best_params_['n_neighbors']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwtdw11OcWE9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "kNc1=KNeighborsClassifier(n_neighbors= best_n_kNc)\n",
        "kNc1.fit(train_X, train_y)\n",
        "pred_kNc=kNc1.predict(test_X)\n",
        "print(\"Accuracy for KNN on CV data: \",accuracy_score(test_y,pred_kNc))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kNc1.fit(train_X, train_y)\n",
        "pred_train_kNc=kNc1.predict(train_X)"
      ],
      "metadata": {
        "id": "4uCufdjti3-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_kNc_T1, precision_kNc_T1, recall_kNc_T1, specificity_kNc_T1, sensitivity_kNc_T1, accuracy_kNc_T2, precision_kNc_T2, recall_kNc_T2,specificity_kNc_T2, sensitivity_kNc_T2 = matrix(train_y,pred_train_kNc,test_y,pred_kNc)"
      ],
      "metadata": {
        "id": "0QVoIYiZi5jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vii. Decision tree (Hyperparameter: min weight fraction leaf)"
      ],
      "metadata": {
        "id": "2kauFx5FkTvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "minimum weight fraction leaf controls the minimum fraction of samples required to be at a leaf node.\n",
        "\n",
        "Considering a range of values for the minimum weight fraction leaf from 0 to 0.5, with a step size of 0.1."
      ],
      "metadata": {
        "id": "dIt7fU8tpHtU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2boViSrhahPX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "dtc = DecisionTreeClassifier()\n",
        "param_grid = {'min_weight_fraction_leaf': np.arange(0, 0.51, 0.1)}\n",
        "CV_dtc = GridSearchCV(estimator=dtc, param_grid=param_grid, cv= 5)\n",
        "CV_dtc.fit(train_X, train_y)\n",
        "best_dtc = CV_dtc.best_params_['min_weight_fraction_leaf']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmHW4l8GahAI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "dtc1=DecisionTreeClassifier(min_weight_fraction_leaf= best_dtc)\n",
        "dtc1.fit(train_X, train_y)\n",
        "pred_dtc=dtc1.predict(test_X)\n",
        "print(\"Accuracy for Decesion Tree on CV data: \",accuracy_score(test_y,pred_dtc))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtc1.fit(train_X, train_y)\n",
        "pred_train_dtc=dtc1.predict(train_X)"
      ],
      "metadata": {
        "id": "vzcMO4p4jQQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_dtc_T1, precision_dtc_T1, recall_dtc_T1, specificity_dtc_T1, sensitivity_dtc_T1, accuracy_dtc_T2, precision_dtc_T2, recall_dtc_T2,specificity_dtc_T2, sensitivity_dtc_T2 = matrix(train_y,pred_train_dtc,test_y,pred_dtc)"
      ],
      "metadata": {
        "id": "7q3wtL4mjQ-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "viii. Random forest (Hyperparameter: number of estimators)"
      ],
      "metadata": {
        "id": "1zt2mOfHkV-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of estimators controls the number of trees in the forest.\n",
        "\n",
        "Considering a range of values for the number of estimators from 0 to 150, with a step size of 50."
      ],
      "metadata": {
        "id": "KIoKDO-HpVKH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqnoR4lVQCwz"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc=RandomForestClassifier()\n",
        "param_grid = {'n_estimators': range(0, 150, 50)}\n",
        "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
        "CV_rfc.fit(train_X, train_y)\n",
        "best_rfc = CV_rfc.best_params_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uL8GYEj9QoTv"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rfc1=RandomForestClassifier(n_estimators= best_dtc)\n",
        "rfc1.fit(train_X, train_y)\n",
        "pred_rfc=rfc1.predict(test_X)\n",
        "print(\"Accuracy for Random Forest on CV data: \",accuracy_score(test_y,pred_rfc))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfc1.fit(train_X, train_y)\n",
        "pred_train_rfc=rfc1.predict(train_X)"
      ],
      "metadata": {
        "id": "lwKyBkE7j71H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_rfc_T1, precision_rfc_T1, recall_rfc_T1, specificity_rfc_T1, sensitivity_rfc_T1, accuracy_rfc_T2, precision_rfc_T2, recall_rfc_T2,specificity_rfc_T2, sensitivity_rfc_T2 = matrix(train_y,pred_train_rfc,test_y,pred_rfc)"
      ],
      "metadata": {
        "id": "R-8tMXFkj8fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "e) Tabulate the accuracy, precision, recall, specificity and senstivity values for training\n",
        "set T1 and test set T2 for each model trained in part (d) for the best hyperparameter choices.\n",
        "Discuss your observations."
      ],
      "metadata": {
        "id": "BvQpBh83qz64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'Model': ['Logistic regression (L2)','Logistic regression (L1)','Soft-margin SVM (L2)', 'Soft-margin SVM (l1)','Kernel SVM with RBF kernel', 'KNN', 'Decision tree', 'Random forest'],\n",
        "              'Train Accuracy': [accuracy_lg_l2_T1,accuracy_lg_l1_T1,accuracy_sm_svm_l2_T1,accuracy_sm_svm_l1_T1,accuracy_svc_T1,accuracy_kNc_T1,accuracy_dtc_T1,accuracy_rfc_T1],\n",
        "              'Train Precision': [precision_lg_l2_T1,precision_lg_l1_T1,precision_sm_svm_l2_T1,precision_sm_svm_l1_T1,precision_svc_T1,precision_kNc_T1,precision_dtc_T1,precision_rfc_T1],\n",
        "              'Train Recall': [recall_lg_l2_T1,recall_lg_l1_T1,recall_sm_svm_l2_T1,recall_sm_svm_l1_T1,recall_svc_T1,recall_kNc_T1,recall_dtc_T1,recall_rfc_T1],\n",
        "              'Train Specificity': [specificity_lg_l2_T1,specificity_lg_l1_T1,specificity_sm_svm_l2_T1,sensitivity_sm_svm_l1_T1,sensitivity_svc_T1,sensitivity_kNc_T1,sensitivity_dtc_T1,sensitivity_rfc_T1],\n",
        "              'Train Sensitivity': [sensitivity_lg_l2_T1,sensitivity_lg_l1_T1,sensitivity_sm_svm_l2_T1,sensitivity_sm_svm_l1_T1,sensitivity_svc_T1,sensitivity_kNc_T1,sensitivity_dtc_T1,sensitivity_rfc_T1],\n",
        "              'Test Accuracy': [accuracy_lg_l2_T2,accuracy_lg_l1_T2,accuracy_sm_svm_l2_T2,accuracy_sm_svm_l1_T2,accuracy_svc_T2,accuracy_kNc_T2,accuracy_dtc_T2,accuracy_rfc_T2],\n",
        "              'Test Precision': [precision_lg_l2_T2,precision_lg_l1_T2,precision_sm_svm_l2_T2,precision_sm_svm_l1_T2,precision_svc_T2,precision_kNc_T2,precision_dtc_T2,precision_rfc_T2],\n",
        "              'Test Recall': [recall_lg_l2_T2,recall_lg_l1_T2,recall_sm_svm_l2_T2,recall_sm_svm_l1_T2,recall_svc_T2,recall_kNc_T2,recall_dtc_T2,recall_rfc_T2],\n",
        "              'Test Specificity': [specificity_lg_l2_T2,specificity_lg_l1_T2,specificity_sm_svm_l2_T2,specificity_sm_svm_l1_T2,specificity_svc_T2,specificity_kNc_T2,specificity_dtc_T2,specificity_rfc_T2],\n",
        "              'Test Sensitivity':  [sensitivity_lg_l2_T2,sensitivity_lg_l1_T2,sensitivity_sm_svm_l2_T2,sensitivity_sm_svm_l1_T2,sensitivity_svc_T2,sensitivity_kNc_T2,sensitivity_dtc_T2,sensitivity_rfc_T2]}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "Z0NxjlD6hDsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "f) Discuss if the L1 regularizers used in logistic regression and soft-margin SVM resulted\n",
        "in sparse models when compared to L2 regularizers. Also compare and contrast the performance\n",
        "of the models obtained using L1 and L2 regularizers. Using these observations, what\n",
        "would you suggest to the practitioner regarding the use of L1 regularizer?"
      ],
      "metadata": {
        "id": "YFdiQd33oPQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nonZero_coef_lg_l2 = np.count_nonzero(lg_l2_1.coef)\n",
        "print(\"Non Zero Coeff for Logistic regression with L2 regularizer = \",nonZero_coef_lg_l2)\n",
        "\n",
        "nonZero_coef_lg_l1 = np.count_nonzero(lg_l1_1.coef)\n",
        "print(\"Non Zero Coeff for Logistic regression with L1 regularizer = \",nonZero_coef_lg_l1)\n",
        "\n",
        "nonZero_coef_sm_svm_l2 = np.count_nonzero(sm_svm_l2.coef)\n",
        "print(\"Non Zero Coeff for Logistic regression with L2 regularizer = \",nonZero_coef_sm_svm_l2)\n",
        "\n",
        "nonZero_coef_sm_svm_l1 = np.count_nonzero(sm_svm_l1.coef)\n",
        "print(\"Non Zero Coeff for Logistic regression with L1 regularizer = \",nonZero_coef_sm_svm_l1)"
      ],
      "metadata": {
        "id": "2l558Cf-pDoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "L1 and L2 regularization are techniques used in machine learning to prevent overfitting and improve model performance. One key difference between these regularization methods is that L1 regularization encourages sparsity in the model, while L2 regularization does not necessarily lead to sparse models.\n",
        "\n",
        "To determine if L1 regularizers used in logistic regression and soft-margin SVM resulted in sparse models when compared to L2 regularizers, i am comparing the number of non-zero coefficients in the resulting models above. L1 regularization tends to produce models with fewer non-zero coefficients than L2 regularization. This is because L1 regularization tends to force some coefficients to zero, effectively removing them from the model and resulting in a sparse model."
      ],
      "metadata": {
        "id": "BSQvgaJ3oRCf"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}